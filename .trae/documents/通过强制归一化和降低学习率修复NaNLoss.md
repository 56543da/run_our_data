**原因分析 (更新)**：

1. **数据分布问题**：虽然数据已在 \[0, 1] 范围内，但神经网络（尤其是 KAN）通常在零均值、单位方差 (Zero Mean, Unit Variance) 的输入下表现更稳定。当前的 MinMax 归一化可能不足以防止深层网络的数值累积误差。
2. **学习率过高**：`1e-4` 对于当前的数据量（特征较少）和模型结构来说可能过于激进，导致训练中途发散。

**修复计划**：

1. **修改** **`train1.py`**：

   * **引入 Z-Score 标准化**：在加载数据后，使用 `sklearn.preprocessing.StandardScaler` 对特征列 (`Age`, `Weight`, `Sex`, `Smoking`) 进行二次归一化。这将把数据转换为均值为 0、方差为 1 的分布，显著提升数值稳定性。

2. **修改** **`run_multi_experiments.ps1`**：

   * **降低学习率**：将所有实验的学习率 (`lr`) 从 `1e-4` 调整为 `5e-5` (或 `1e-5`，视稳定性需求而定，建议先尝试 `5e-5`)。

   * **保持梯度裁剪阈值不变** (按您要求)。

**注意**：

* 您提到的 `G_first_last_nor.csv` 仅包含 4 个特征是正常的，模型将自适应这 4 个特征进行训练。

* `train1.py` 中丢弃重复 ID 的逻辑是正确的（用于构建查询字典），不会影响数据加载器中的过采样逻辑。
