# 超参数分析与故障排除指南

这份文档为您详细解释 `run_multi_experiments.ps1` 中的所有超参数原理，分析 SGD 实验中遇到的高特异性/低敏感度问题，并提供调整策略。

## 1. 核心超参数详解

以下是您脚本中使用的关键超参数及其作用：

| 参数名 | 默认值/示例 | 含义与作用 |
| :--- | :--- | :--- |
| **`model`** | `MMCAF_Net` | **模型架构**。指定使用哪个模型类（定义在 `models/` 目录下）。 |
| **`dataset`** | `pe` | **数据集名称**。告诉代码加载哪个 Dataset 类（例如 `datasets/ct_pe_dataset_3d.py`）。 |
| **`learning_rate` (LR)** | `5e-5` (Adam)<br>建议`1e-2`，实测1e-3can not,but1e-2 could (SGD) | **学习率**。决定模型权重更新的步长。<br>- **过大**：无法收敛，Loss 震荡。<br>- **过小**：训练极慢，容易陷入局部最优。 |
| **`batch_size`** | `32` | **批次大小**。一次迭代中处理的样本数。<br>- **大**：梯度更稳定，但占用更多显存。<br>- **小**：引入更多噪声（有助于泛化），但训练波动大。 |
| **`optimizer`** | `adam` / `sgd` | **优化器**。<br>- **Adam**：自适应学习率，收敛快，适合初学者，但在某些图像任务上泛化性略差。<br>- **SGD**：随机梯度下降，泛化性通常更好，但需要精细调节 LR 和动量。 |
| **`weight_decay`** | `1e-2` (Adam)<br>`1e-4` (SGD) | **权重衰减 (L2 正则化)**。防止模型过拟合。<br>- **过大**：模型欠拟合，Loss 降不下去。<br>- **过小**：模型过拟合，训练集 Acc 高但验证集差。 |
| **`sgd_momentum`** | `0.9` | **SGD 动量**。帮助 SGD 冲过局部极小值并加速收敛。<br>- 推荐值：`0.9`。 |
| **`sgd_dampening`** | `0` (修复后) | **SGD 阻尼**。抑制动量。<br>- **重要**：如果不为 0（如之前的 0.9），会严重阻碍模型学习新梯度，导致 Loss 不降。 |
| **`num_epochs`** | `50` / `100` | **训练轮数**。模型遍历整个训练集的次数。 |
| **`ablation_eval_freq`** | `5` | **消融实验频率**。每隔多少 Epoch 跑一次单模态测试（仅图像/仅表格）。<br>- 设为 `0` 可关闭以节省时间。 |
| **`data_dir`** | `../data` | **数据根目录**。存放 `series_list.pkl`, `data.hdf5` 和 CSV 的位置。 |
| **`save_dir`** | `../train_result` | **结果保存目录**。日志、Checkpoints 和 TensorBoard 文件的输出位置。 |
| **`gpu_ids`** | `0` | **GPU 编号**。指定使用哪块显卡进行训练（例如 `0` 或 `0,1`）。 |
| **`iters_per_print`** | `32` | **日志打印频率**。每训练多少个 Batch 在终端打印一次 Loss。通常设为与 Batch Size 相同。 |
| **`iters_per_visual`** | `8000` | **可视化频率**。每多少个 Iteration 在 TensorBoard 中记录一次图像/Attention Map。设得大一些以节省磁盘空间。 |
| **`lr_decay_step`** | `600000` | **学习率衰减步数**。仅在使用 StepLR 时有效，表示多少步后降低学习率。 |
| **`lr_scheduler`** | `cosine_warmup` | **学习率调度器**。<br>- `cosine_warmup`：先热身（逐渐增加 LR），然后按余弦曲线下降。通常效果最好。 |
| **`num_slices`** | `12` | **切片数量**。输入模型的 3D 图像的深度（Z轴）。模型会从原始影像中采样出 12 张切片。 |
| **`phase`** | `train` | **运行阶段**。`train` 表示训练模式，`test` 表示测试模式。 |
| **`agg_method`** | `max` | **聚合方法**。如果一个序列被切分为多个样本，如何聚合预测结果（取最大值 `max` 或平均值 `mean`）。 |
| **`best_ckpt_metric`** | `val_loss` | **最佳模型指标**。根据哪个指标来判定“最佳模型”并保存 `best.pth.tar`。通常用 `val_loss` 或 `val_AUROC`。 |
| **`crop_shape`** | `192,192` | **裁剪尺寸**。数据增强时的随机裁剪大小 (H, W)。 |
| **`cudnn_benchmark`** | `True` | **cuDNN 加速**。开启后会根据硬件自动寻找最快的卷积算法。输入尺寸固定时推荐开启。 |
| **`do_classify`** | `True` | **执行分类任务**。该标志位用于控制模型是否输出分类 Logits。 |
| **`epochs_per_eval`** | `1` | **评估频率**。每隔多少个 Epoch 在验证集上跑一次完整测试。 |
| **`epochs_per_save`** | `1` | **保存频率**。每隔多少个 Epoch 保存一次 Checkpoint。 |
| **`shap_eval_freq`** | `5` | **SHAP 分析频率**。每隔多少 Epoch 运行一次 SHAP 可解释性分析（较耗时）。 |
| **`fine_tune`** | `False` | **微调模式**。是否加载预训练模型并冻结部分层进行微调。 |
| **`fine_tuning_boundary`** | `classifier` | **微调边界**。指定从哪一层开始解冻参数（例如只训练最后的分类器）。 |
| **`fine_tuning_lr`** | `1e-2` | **微调学习率**。微调层的特定学习率。 |
| **`include_normals`** | `True` | **包含正常样本**。是否在训练中包含标签为 0 的样本。 |
| **`lr_warmup_steps`** | `1500` | **热身步数**。学习率从 0 增加到目标值所需的 Iteration 次数。对于当前数据集 (Batch=32)，建议设置为 1500 (约占 50 Epochs 总步数的 10%)。 |
| **`model_depth`** | `50` | **ResNet 深度**。图像编码器的骨干网络深度（如 ResNet-50）。 |
| **`num_classes`** | `1` | **类别数量**。二分类任务设为 1（输出 Logits），多分类设为 N。 |
| **`num_visuals`** | `8` | **可视化数量**。在 TensorBoard 中展示多少张示例图片。 |
| **`num_workers`** | `8` | **数据加载线程数**。用于 DataLoader。CPU 核心数越多，数据加载越快。 |
| **`pe_types`** | `['central','segmental']` | **PE 类型**。用于过滤肺栓塞的具体亚型（如中心型、节段型）。仅在数据集包含此元数据且代码未禁用过滤逻辑时生效。 |
| **`resize_shape`** | `192,192` | **缩放尺寸**。图像输入模型的统一尺寸。 |
| **`use_pretrained`** | `False` | **使用预训练权重**。是否加载 ImageNet 等预训练权重。 |

---

## 2. 问题诊断：Sensitivity (敏感度) 低，Specificity (特异性) 高

您在 SGD 实验中观察到 **Sensitivity ≈ 0.1 (低)** 而 **Specificity ≈ 0.9 (高)**。这在医疗 AI 中非常典型，称为 **"预测全阴性" (All-Negative Prediction)** 陷阱。

### 原因分析

1. **类别不平衡 (Class Imbalance)**：验证集中负样本（无病）远多于正样本（有病）。

   * 假设验证集有 100 个样本：90 个负，10 个正。

   * 模型只要无脑预测“全负”，就能得到 90% 的 Accuracy 和 100% 的 Specificity。

   * SGD 在寻找“最快降低 Loss”的路径时，发现“全猜负”是一条捷径。
2. **阈值不敏感**：默认分类阈值为 `0.5`。对于不平衡数据，模型输出的正样本概率往往偏低（例如 0.3-0.4），导致即使模型“觉得”有点像正样本，也被阈值卡成了负样本。

### 解决方案

#### 方案 A：调整分类阈值 (首选策略)

由于您已经在训练集中使用了 **随机过采样 (Random Over Sampling, ROS)**，模型在训练时已经看到了平衡的类别分布。

*   **现状**：训练时正负样本 1:1，但验证集仍然保持原始的不平衡分布（负多正少）。模型输出的概率可能会整体偏向于负类（< 0.5）。
*   **操作**：**不要**再次添加 Class Weights（避免双重加权）。正确的做法是调整验证时的分类阈值。
*   **依据**：观察验证集的 **ROC 曲线**。选择曲线左上角最接近 (0,1) 的点对应的阈值。
*   **实践**：如果 Sensitivity 过低，尝试在推理/评估时将阈值从 `0.5` 降低到 `0.2` 或 `0.3`。

#### 方案 B：使用类别权重 (Class Weights) (备选)

仅当您关闭了 ROS（过采样）或者过采样效果不佳时，才考虑在 Loss 函数中添加权重。目前不推荐。

---

## 3. 基准线：空准确率 (Null Accuracy)

**空准确率**是判断模型是否“学到了东西”的底线。

### 定义

如果不看任何数据，只猜“出现最多的那个类别”，准确率是多少？

$$ \text{Null Accuracy} = \frac{\max(\text{负样本数}, \text{正样本数})}{\text{总样本数}} $$

### 如何计算您的数据？

您的训练脚本 `train1.py` 现在会在启动时自动计算并打印验证集的空准确率。

* **如果 Null Accuracy = 85%**，而您的模型跑出 **86%**，说明模型**几乎无效**。

* **如果 Null Accuracy = 85%**，而您的模型跑出 **92%**，说明模型**有效**。

---

## 4. 建议调整步骤

1. **观察基准**：查看训练开始时输出的 `Null Accuracy`。
2. **清理 TensorBoard**：在 `model_evaluator1.py` 中注释掉 `ablation_metrics` 相关的写入代码（如果不想要这些图）。
3. **微调 SGD**：

   * 保持 `sgd_dampening = 0`。

   * 尝试 `learning_rate = 1e-2`。

4. **观察指标**：不要只看 Accuracy，要看 **AUROC** 和 **F1-Score**，这两个指标对不平衡数据更敏感。
