# 重构数据管道以支持显式训练验证集划分

基于您的需求和对现有代码的分析，这是实施计划。

### 1. 修改 `preprocess_data.py` (数据处理与划分)
我们将重构脚本以支持显式的训练/验证目录和匹配的 Excel 工作表。

*   **输入参数**:
    *   将单个 `--dcm_root` 替换为 `--train_dir` (默认: `E:\Lung_org_data\lung(train)`) 和 `--val_dir` (默认: `E:\Lung_org_data\lung(val)`)。
    *   保留 `--meta_file` (默认: `E:\run_our_data\data\原始STAS_data.xlsx`)。
*   **Excel 逻辑**:
    *   读取工作表 **'train+test data'** 作为 **训练集** 的元数据。
    *   读取工作表 **'external validation'** 作为 **验证集** 的元数据。
*   **处理流程**:
    *   **训练数据**: 扫描 `train_dir`，匹配训练元数据，分配 `parser='train'`。
    *   **验证数据**: 扫描 `val_dir`，匹配验证元数据，分配 `parser='val'`。
    *   **过采样**: 应用随机过采样 (ROS) **仅针对 'train' 子集** 以平衡正负样本。
    *   **合并**: 将两个集合合并为 `G_first_last_nor.csv`。

### 2. 修改 `hdf5_ours.py` (HDF5 打包)
我们将使脚本更灵活以处理新的目录结构。

*   **递归搜索**: 更新文件扫描逻辑，递归搜索给定根目录下的 `Lung.nii` 文件。
*   **用法**: 您将使用 `--dcm_root "E:\Lung_org_data"` 运行此脚本。它将自动找到 `lung(train)` 和 `lung(val)` 文件夹中的所有图像，并将它们打包成单个 `data.hdf5` 文件。

### 3. 执行与验证
修改代码后，我将按正确顺序执行脚本以生成新的数据集文件：
1.  运行 `preprocess_data.py` 生成新的 CSV。
2.  运行 `hdf5_ours.py` 生成新的 HDF5。
3.  运行 `pkl_read.py` 更新 Pickle 索引。

**注意**: `train1.py` 不需要修改，因为它读取生成的 `.pkl` 文件，该文件现在将包含正确的包含手动划分。
